<!doctype html><html lang=en-us dir=ltr><head><meta charset=utf-8><meta name=viewport content='width=device-width,initial-scale=1'><meta name=description content="初识 Hadoop 前言 本系列文章是基于《大数据技术基础》与 10 小时入门大数据 课程，如果有兴趣可以先阅读该书并观看视频教程。本系列文章中所用到的软件版本及其下载地址如下：\n"><title>初识 Hadoop</title><link rel=canonical href=https://jinggqu.github.io/posts/getting-to-know-hadoop/><link rel=stylesheet href=/scss/style.min.6a692fd055deae459f2a9767f57f3855ba80cafd5041317f24f7360f6ca47cdf.css><meta property='og:title' content="初识 Hadoop"><meta property='og:description' content="初识 Hadoop 前言 本系列文章是基于《大数据技术基础》与 10 小时入门大数据 课程，如果有兴趣可以先阅读该书并观看视频教程。本系列文章中所用到的软件版本及其下载地址如下：\n"><meta property='og:url' content='https://jinggqu.github.io/posts/getting-to-know-hadoop/'><meta property='og:site_name' content="Anthony's blog"><meta property='og:type' content='article'><meta property='article:section' content='Post'><meta property='article:published_time' content='2020-09-24T09:20:11+08:00'><meta property='article:modified_time' content='2020-09-24T09:20:11+08:00'><meta name=twitter:title content="初识 Hadoop"><meta name=twitter:description content="初识 Hadoop 前言 本系列文章是基于《大数据技术基础》与 10 小时入门大数据 课程，如果有兴趣可以先阅读该书并观看视频教程。本系列文章中所用到的软件版本及其下载地址如下：\n"></head><body class=article-page><script>(function(){const e="StackColorScheme";localStorage.getItem(e)||localStorage.setItem(e,"auto")})()</script><script>(function(){const t="StackColorScheme",e=localStorage.getItem(t),n=window.matchMedia("(prefers-color-scheme: dark)").matches===!0;e=="dark"||e==="auto"&&n?document.documentElement.dataset.scheme="dark":document.documentElement.dataset.scheme="light"})()</script><div class="container main-container flex on-phone--column extended"><aside class="sidebar left-sidebar sticky"><button class="hamburger hamburger--spin" type=button id=toggle-menu aria-label="Toggle Menu">
<span class=hamburger-box><span class=hamburger-inner></span></span></button><header><figure class=site-avatar><a href=/><img src=/img/avatar_hu_fd6b132a83bc2f5d.webp width=300 height=300 class=site-logo loading=lazy alt=Avatar></a></figure><div class=site-meta><h1 class=site-name><a href=/>Anthony's blog</a></h1><h2 class=site-description></h2></div></header><ol class=menu id=main-menu><li><a href=/><svg class="icon icon-tabler icon-tabler-home" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><polyline points="5 12 3 12 12 3 21 12 19 12"/><path d="M5 12v7a2 2 0 002 2h10a2 2 0 002-2v-7"/><path d="M9 21v-6a2 2 0 012-2h2a2 2 0 012 2v6"/></svg>
<span>Home</span></a></li><li><a href=/archives><svg class="icon icon-tabler icon-tabler-archive" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><rect x="3" y="4" width="18" height="4" rx="2"/><path d="M5 8v10a2 2 0 002 2h10a2 2 0 002-2V8"/><line x1="10" y1="12" x2="14" y2="12"/></svg>
<span>Archives</span></a></li><li><a href=/search><svg class="icon icon-tabler icon-tabler-search" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="10" cy="10" r="7"/><line x1="21" y1="21" x2="15" y2="15"/></svg>
<span>Search</span></a></li><li><a href=https://github.com/jinggqu target=_blank><svg class="icon icon-tabler icon-tabler-brand-github" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M9 19c-4.3 1.4-4.3-2.5-6-3m12 5v-3.5c0-1 .1-1.4-.5-2 2.8-.3 5.5-1.4 5.5-6a4.6 4.6.0 00-1.3-3.2 4.2 4.2.0 00-.1-3.2s-1.1-.3-3.5 1.3a12.3 12.3.0 00-6.2.0C6.5 2.8 5.4 3.1 5.4 3.1a4.2 4.2.0 00-.1 3.2A4.6 4.6.0 004 9.5c0 4.6 2.7 5.7 5.5 6-.6.6-.6 1.2-.5 2V21"/></svg>
<span>GitHub</span></a></li><li><a href=https://unsplash.com/@xvyn target=_blank><svg class="icon icon-tabler icon-tabler-link" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><path d="M10 14a3.5 3.5.0 005 0l4-4a3.5 3.5.0 00-5-5l-.5.5"/><path d="M14 10a3.5 3.5.0 00-5 0l-4 4a3.5 3.5.0 005 5l.5-.5"/></svg>
<span>Unsplash</span></a></li><li><a href=/index.xml target=_blank><svg class="icon icon-tabler icon-tabler-rss" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="5" cy="19" r="1"/><path d="M4 4a16 16 0 0116 16"/><path d="M4 11a9 9 0 019 9"/></svg>
<span>RSS</span></a></li><li class=menu-bottom-section><ol class=menu><li id=dark-mode-toggle><svg class="icon icon-tabler icon-tabler-toggle-left" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="8" cy="12" r="2"/><rect x="2" y="6" width="20" height="12" rx="6"/></svg>
<svg class="icon icon-tabler icon-tabler-toggle-right" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="16" cy="12" r="2"/><rect x="2" y="6" width="20" height="12" rx="6"/></svg>
<span>Dark Mode</span></li></ol></li></ol></aside><aside class="sidebar right-sidebar sticky"><section class="widget archives"><div class=widget-icon><svg class="icon icon-tabler icon-tabler-hash" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><line x1="5" y1="9" x2="19" y2="9"/><line x1="5" y1="15" x2="19" y2="15"/><line x1="11" y1="4" x2="7" y2="20"/><line x1="17" y1="4" x2="13" y2="20"/></svg></div><h2 class="widget-title section-title">Table of contents</h2><div class=widget--toc><nav id=TableOfContents><ol><li><a href=#前言>前言</a></li><li><a href=#环境准备>环境准备</a><ol><li><a href=#配置网络>配置网络</a></li><li><a href=#配置-host>配置 host</a></li><li><a href=#配置-jdk>配置 JDK</a><ol><li><a href=#修改-bash_profile>修改 bash_profile</a></li></ol></li><li><a href=#配置-ssh-免密钥登录>配置 SSH 免密钥登录</a></li></ol></li><li><a href=#完善配置>完善配置</a><ol><li><a href=#安装-hadoop>安装 Hadoop</a></li><li><a href=#修改配置文件>修改配置文件</a><ol><li><a href=#编辑-core-sitexml>编辑 core-site.xml</a></li><li><a href=#编辑-hdfs-sitexml>编辑 hdfs-site.xml</a></li><li><a href=#编辑-yarn-sitexml>编辑 yarn-site.xml</a></li><li><a href=#编辑-mapred-sitexml>编辑 mapred-site.xml</a></li><li><a href=#编辑-slaves>编辑 slaves</a></li></ol></li><li><a href=#复制文件到子节点>复制文件到子节点</a></li><li><a href=#配置-hadoop-环境变量>配置 Hadoop 环境变量</a></li><li><a href=#创建临时文件存放目录>创建临时文件存放目录</a></li></ol></li><li><a href=#启动集群>启动集群</a><ol><li><a href=#格式化文件系统>格式化文件系统</a></li><li><a href=#启动-hadoop-集群>启动 Hadoop 集群</a></li><li><a href=#查看进程是否启动成功>查看进程是否启动成功</a></li><li><a href=#查看-webui>查看 WebUI</a><ol><li><a href=#hadoop-页面>Hadoop 页面</a></li><li><a href=#yarn-页面>YARN 页面</a></li></ol></li></ol></li><li><a href=#运行实例>运行实例</a></li><li><a href=#备注>备注</a></li></ol></nav></div></section></aside><main class="main full-width"><article class=main-article><header class=article-header><div class=article-details><header class=article-category><a href=/categories/hadoop/>Hadoop</a></header><div class=article-title-wrapper><h2 class=article-title><a href=/posts/getting-to-know-hadoop/>初识 Hadoop</a></h2></div><footer class=article-time><div><svg class="icon icon-tabler icon-tabler-calendar-time" width="56" height="56" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><path d="M11.795 21H5a2 2 0 01-2-2V7a2 2 0 012-2h12a2 2 0 012 2v4"/><circle cx="18" cy="18" r="4"/><path d="M15 3v4"/><path d="M7 3v4"/><path d="M3 11h16"/><path d="M18 16.496V18l1 1"/></svg>
<time class=article-time--published>Sep 24, 2020</time></div></footer></div></header><section class=article-content><h1 id=初识-hadoop>初识 Hadoop</h1><h2 id=前言>前言</h2><p>本系列文章是基于《大数据技术基础》与 <a class=link href=https://coding.imooc.com/class/128.html target=_blank rel=noopener>10 小时入门大数据</a> 课程，如果有兴趣可以先阅读该书并观看视频教程。本系列文章中所用到的软件版本及其下载地址如下：</p><div class=table-wrapper><table><thead><tr><th>名称</th><th>版本</th><th>下载地址</th></tr></thead><tbody><tr><td>CentOS</td><td>8.2.2004</td><td><a class=link href=https://mirrors.tuna.tsinghua.edu.cn/centos/8.2.2004/isos/x86_64/CentOS-8.2.2004-x86_64-minimal.iso target=_blank rel=noopener>https://mirrors.tuna.tsinghua.edu.cn/centos/8.2.2004/isos/x86_64/CentOS-8.2.2004-x86_64-minimal.iso</a></td></tr><tr><td>JDK</td><td>14.0.2</td><td><a class=link href=https://www.oracle.com/java/technologies/javase/jdk14-archive-downloads.html target=_blank rel=noopener>https://www.oracle.com/java/technologies/javase/jdk14-archive-downloads.html</a></td></tr><tr><td>Hadoop</td><td>2.10.1</td><td><a class=link href=https://www.apache.org/dyn/closer.cgi/hadoop/common/hadoop-2.10.1/hadoop-2.10.1-src.tar.gz target=_blank rel=noopener>https://www.apache.org/dyn/closer.cgi/hadoop/common/hadoop-2.10.1/hadoop-2.10.1-src.tar.gz</a></td></tr></tbody></table></div><h2 id=环境准备>环境准备</h2><h3 id=配置网络>配置网络</h3><p>此篇文章所使用的 CentOS 环境均是使用 VMware 15 虚拟的，具体安装教程请查看 <a class=link href=https://www.cnblogs.com/bobo-pcb/p/11708459.html target=_blank rel=noopener>使用 VMware 15 安装虚拟机和使用 CentOS 8</a>，此处不再赘述。安装好一个节点之后，我们可以采用“虚拟机克隆”的方式，直接完成另外两个节点系统的安装。</p><p>虚拟机的网络配置采用 DHCP 自动分配模式，每台机器的 IP 地址可以通过命令 <code>ip address</code> 或 <code>ifconfig</code> 查看，其中 <code>ifconfig</code> 输出如下，第一组配置中 <code>ens33</code> 即为本机网络配置，<code>inet</code> 项对应的即为本机 ip（192.168.61.128）。</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-text data-lang=text><span class=line><span class=cl>ens33: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt;  mtu 1500
</span></span><span class=line><span class=cl>        inet 192.168.61.128  netmask 255.255.255.0  broadcast 192.168.61.255
</span></span><span class=line><span class=cl>        inet6 fe80::20c:29ff:fe65:9052  prefixlen 64  scopeid 0x20&lt;link&gt;
</span></span><span class=line><span class=cl>        ether 00:0c:29:65:90:52  txqueuelen 1000  (Ethernet)
</span></span><span class=line><span class=cl>        RX packets 38037  bytes 6542757 (6.2 MiB)
</span></span><span class=line><span class=cl>        RX errors 0  dropped 0  overruns 0  frame 0
</span></span><span class=line><span class=cl>        TX packets 30479  bytes 16809162 (16.0 MiB)
</span></span><span class=line><span class=cl>        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>lo: flags=73&lt;UP,LOOPBACK,RUNNING&gt;  mtu 65536
</span></span><span class=line><span class=cl>        inet 127.0.0.1  netmask 255.0.0.0
</span></span><span class=line><span class=cl>        inet6 ::1  prefixlen 128  scopeid 0x10&lt;host&gt;
</span></span><span class=line><span class=cl>        loop  txqueuelen 1000  (Local Loopback)
</span></span><span class=line><span class=cl>        RX packets 23656  bytes 13542580 (12.9 MiB)
</span></span><span class=line><span class=cl>        RX errors 0  dropped 0  overruns 0  frame 0
</span></span><span class=line><span class=cl>        TX packets 23656  bytes 13542580 (12.9 MiB)
</span></span><span class=line><span class=cl>        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>virbr0: flags=4099&lt;UP,BROADCAST,MULTICAST&gt;  mtu 1500
</span></span><span class=line><span class=cl>        ether 52:54:00:d2:b3:31  txqueuelen 1000  (Ethernet)
</span></span><span class=line><span class=cl>        RX packets 0  bytes 0 (0.0 B)
</span></span><span class=line><span class=cl>        RX errors 0  dropped 0  overruns 0  frame 0
</span></span><span class=line><span class=cl>        TX packets 0  bytes 0 (0.0 B)
</span></span><span class=line><span class=cl>        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0
</span></span></code></pre></td></tr></table></div></div><p>本篇文章中三台集群的 IP 分别如下，下文中不再赘述。</p><div class=table-wrapper><table><thead><tr><th style=text-align:center>主机名</th><th style=text-align:center>IP</th></tr></thead><tbody><tr><td style=text-align:center>master</td><td style=text-align:center>192.168.61.128</td></tr><tr><td style=text-align:center>slave1</td><td style=text-align:center>192.168.61.129</td></tr><tr><td style=text-align:center>slave2</td><td style=text-align:center>192.168.61.131</td></tr></tbody></table></div><h3 id=配置-host>配置 host</h3><p>以上三台机器要搭建成为集群，就需要让它们互相认识。这个认识的过程是通过 <code>/etc/hosts</code> 文件来实现的。这一步需要修改每一台机器的 hosts 文件，将以下内容分别粘贴到各个机器的 hosts 文件中。</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>vim /etc/hosts
</span></span></code></pre></td></tr></table></div></div><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>192.168.61.128 master
</span></span><span class=line><span class=cl>192.168.61.129 slave1
</span></span><span class=line><span class=cl>192.168.61.131 slave2
</span></span></code></pre></td></tr></table></div></div><h3 id=配置-jdk>配置 JDK</h3><p>因为 Hadoop 的环境依赖于 Java JDK，所以需要确保虚拟机中已经正确安装了 JDK，除此之外我们还需要将 JDK 地址配置到环境变量中。在本例中，我的 JDK 安装位置是 <code>/usr/java/jdk-14.0.2</code>。</p><h4 id=修改-bash_profile>修改 bash_profile</h4><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>vim ~/.bash_profile
</span></span></code></pre></td></tr></table></div></div><p>添加以下内容到 .bash_profile 文件末尾：</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-gdscript3 data-lang=gdscript3><span class=line><span class=cl><span class=k>export</span> <span class=n>JAVA_HOME</span><span class=o>=/</span><span class=n>usr</span><span class=o>/</span><span class=n>java</span><span class=o>/</span><span class=n>jdk</span><span class=o>-</span><span class=mf>14.0</span><span class=o>.</span><span class=mi>2</span>
</span></span><span class=line><span class=cl><span class=k>export</span> <span class=n>PATH</span><span class=o>=$</span><span class=n>JAVA_HOME</span><span class=o>/</span><span class=n>bin</span><span class=p>:</span><span class=o>$</span><span class=n>PATH</span>
</span></span></code></pre></td></tr></table></div></div><p>修改完成并保存后，还需要执行 <code>source</code> 命令使环境变量立即生效。</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=nb>source</span> ~/.bash_profile
</span></span></code></pre></td></tr></table></div></div><p>然后即可使用 <code>java -version</code> 检查环境变量是否配置成功，执行结果如下所示。</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>java version &#34;14.0.2&#34; 2020-07-14
</span></span><span class=line><span class=cl>Java(TM) SE Runtime Environment (build 14.0.2+12-46)
</span></span><span class=line><span class=cl>Java HotSpot(TM) 64-Bit Server VM (build 14.0.2+12-46, mixed mode, sharing)
</span></span></code></pre></td></tr></table></div></div><h3 id=配置-ssh-免密钥登录>配置 SSH 免密钥登录</h3><p>在 Linux 集群间配置免密钥登录，是 Hadoop 集群运维的基础。以下操作在 master 节点进行，实现从 master 免密钥登录 slave1、slave2 节点。生成 ssh 密钥的命令如下：</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>ssh-keygen
</span></span></code></pre></td></tr></table></div></div><p>生成过程中会有一些提示，一路回车即可。执行结果如下所示。</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>root@master:/usr/local/software## ssh-keygen
</span></span><span class=line><span class=cl>Generating public/private rsa key pair.
</span></span><span class=line><span class=cl>Enter file in which to save the key (/root/.ssh/id_rsa):
</span></span><span class=line><span class=cl>/root/.ssh/id_rsa already exists.
</span></span><span class=line><span class=cl>Overwrite (y/n)? y
</span></span><span class=line><span class=cl>Enter passphrase (empty for no passphrase):
</span></span><span class=line><span class=cl>Enter same passphrase again:
</span></span><span class=line><span class=cl>Your identification has been saved in /root/.ssh/id_rsa.
</span></span><span class=line><span class=cl>Your public key has been saved in /root/.ssh/id_rsa.pub.
</span></span><span class=line><span class=cl>The key fingerprint is:
</span></span><span class=line><span class=cl>SHA256:DC7+sETaazn0f4OVgxozjdw2XM1Tb60cqoaQvDGXpg8 root@master
</span></span><span class=line><span class=cl>The key&#39;s randomart image is:
</span></span><span class=line><span class=cl>+---[RSA 3072]----+
</span></span><span class=line><span class=cl>|                 |
</span></span><span class=line><span class=cl>|              .  |
</span></span><span class=line><span class=cl>|      .    o . ..|
</span></span><span class=line><span class=cl>|     . o  . + . +|
</span></span><span class=line><span class=cl>|    oo.*S+ . + + |
</span></span><span class=line><span class=cl>|   =..% @ + . o  |
</span></span><span class=line><span class=cl>|  ..=oE## = o     |
</span></span><span class=line><span class=cl>|   .+==.o =      |
</span></span><span class=line><span class=cl>|   .o..ooo .     |
</span></span><span class=line><span class=cl>+----[SHA256]-----+
</span></span></code></pre></td></tr></table></div></div><p>接下来需要将生成的公钥上传到 slave1 节点，命令如下：</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>ssh-copy-id root@slave1
</span></span></code></pre></td></tr></table></div></div><p>首次通过 master 终端将公钥传给 salve 终端，需要输入 slave 节点的登录密码。上述命令中我们是传输到 slave1 的 root 账户下，所以需要输入 root 用户的密码，传送完毕即可实现免密码登录。执行结果如下。</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>root@master:/usr/local/software## ssh-copy-id root@slave1
</span></span><span class=line><span class=cl>/usr/bin/ssh-copy-id: INFO: Source of key(s) to be installed: &#34;/root/.ssh/id_rsa.pub&#34;
</span></span><span class=line><span class=cl>/usr/bin/ssh-copy-id: INFO: attempting to log in with the new key(s), to filter out any that are already installed
</span></span><span class=line><span class=cl>/usr/bin/ssh-copy-id: INFO: 1 key(s) remain to be installed -- if you are prompted now it is to install the new keys
</span></span><span class=line><span class=cl>root@slave1&#39;s password:
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>Number of key(s) added: 1
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>Now try logging into the machine, with:   &#34;ssh &#39;root@slave1&#39;&#34;
</span></span><span class=line><span class=cl>and check to make sure that only the key(s) you wanted were added.
</span></span></code></pre></td></tr></table></div></div><p>slave2 节点命令同上，只需更改传送到的节点名称，执行结果如下。</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>root@master:/usr/local/software## ssh-copy-id root@slave2
</span></span><span class=line><span class=cl>/usr/bin/ssh-copy-id: INFO: Source of key(s) to be installed: &#34;/root/.ssh/id_rsa.pub&#34;
</span></span><span class=line><span class=cl>/usr/bin/ssh-copy-id: INFO: attempting to log in with the new key(s), to filter out any that are already installed
</span></span><span class=line><span class=cl>/usr/bin/ssh-copy-id: INFO: 1 key(s) remain to be installed -- if you are prompted now it is to install the new keys
</span></span><span class=line><span class=cl>root@slave2&#39;s password:
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>Number of key(s) added: 1
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>Now try logging into the machine, with:   &#34;ssh &#39;root@slave2&#39;&#34;
</span></span><span class=line><span class=cl>and check to make sure that only the key(s) you wanted were added.
</span></span></code></pre></td></tr></table></div></div><p>现在可以尝试登录子节点 slave1 和 slave2。</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>ssh root@slave1
</span></span></code></pre></td></tr></table></div></div><p>成功登录 salve1 节点的提示如下。</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>root@master:/usr/local/software## ssh root@slave1
</span></span><span class=line><span class=cl>Web console: https://slave1:9090/ or https://192.168.61.129:9090/
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>Last login: Fri Sep 24 14:56:46 2020 from 192.168.61.1
</span></span></code></pre></td></tr></table></div></div><h2 id=完善配置>完善配置</h2><p>以下配置均在 master 节点上完成，配置完成后可直接复制到 slave 节点，以免重复劳动。</p><h3 id=安装-hadoop>安装 Hadoop</h3><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=nb>cd</span> /usr/local/software
</span></span><span class=line><span class=cl>wget http://mirror.cogentco.com/pub/apache/hadoop/common/hadoop-2.10.1/hadoop-2.10.1-src.tar.gz
</span></span><span class=line><span class=cl>tar -zxvf hadoop-2.10.1-src.tar.gz
</span></span><span class=line><span class=cl><span class=nb>cd</span> hadoop-2.10.1-src
</span></span><span class=line><span class=cl>mv * ~/hadoop
</span></span></code></pre></td></tr></table></div></div><p>在正式使用 Hadoop 集群之前，我们还需要对其配置文件进行修改。本节中的配置内容请以 <a class=link href=https://hadoop.apache.org/docs/stable/hadoop-project-dist/hadoop-common/SingleCluster.html target=_blank rel=noopener>官方文档</a> 为准。</p><p>Hadoop 的配置文件均存放在 Hadoop 所在目录的 /etc/hadoop/ 文件夹下。</p><h3 id=修改配置文件>修改配置文件</h3><h4 id=编辑-core-sitexml>编辑 core-site.xml</h4><p>文件 core-site.xml 用来配置 Hadoop 集群的通用属性，包括指定 NameNode 的地址、指定使用 Hadoop 时临时文件的存放路径、指定检查点备份日志的最长时间等。</p><p>使用 vim 打开文件：</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>vim ~/hadoop-2.10.1/etc/hadoop/core-site.xml
</span></span></code></pre></td></tr></table></div></div><p>使用以下内容替换 core-site.xml 中的内容：</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-xml data-lang=xml><span class=line><span class=cl><span class=cp>&lt;?xml version=&#34;1.0&#34; encoding=&#34;UTF-8&#34;?&gt;</span>
</span></span><span class=line><span class=cl><span class=cp>&lt;?xml-stylesheet type=&#34;text/xsl&#34; href=&#34;configuration.xsl&#34;?&gt;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=nt>&lt;configuration&gt;</span>
</span></span><span class=line><span class=cl>    <span class=c>&lt;!-- 指定 namenode 的地址 --&gt;</span>
</span></span><span class=line><span class=cl>    <span class=nt>&lt;property&gt;</span>
</span></span><span class=line><span class=cl>        <span class=nt>&lt;name&gt;</span>fs.defaultFS<span class=nt>&lt;/name&gt;</span>
</span></span><span class=line><span class=cl>        <span class=nt>&lt;value&gt;</span>hdfs://master:9000<span class=nt>&lt;/value&gt;</span>
</span></span><span class=line><span class=cl>    <span class=nt>&lt;/property&gt;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c>&lt;!-- 指定使用 Hadoop 时临时文件的存放路径 --&gt;</span>
</span></span><span class=line><span class=cl>    <span class=nt>&lt;property&gt;</span>
</span></span><span class=line><span class=cl>        <span class=nt>&lt;name&gt;</span>hadoop.tmp.dir<span class=nt>&lt;/name&gt;</span>
</span></span><span class=line><span class=cl>        <span class=nt>&lt;value&gt;</span>/home/hadoop/temp<span class=nt>&lt;/value&gt;</span>
</span></span><span class=line><span class=cl>    <span class=nt>&lt;/property&gt;</span>
</span></span><span class=line><span class=cl><span class=nt>&lt;/configuration&gt;</span>
</span></span></code></pre></td></tr></table></div></div><p>第 6<del>9 行配置 fs.defaultFS 的属性为 hdfs://master:9000，master 是主机名；第 12</del>15 行指定 Hadoop 的临时文件夹为 /home/hadoop/temp，此文件夹用户可以自己指定。</p><h4 id=编辑-hdfs-sitexml>编辑 hdfs-site.xml</h4><p>文件 hdfs-site.xml 用来配置分布式文件系统 HDFS 的属性，包括指定 HDFS 保存数据的副本数量，指定 HDFS 中 NameNode、DataNode 的存储位置等。</p><p>使用 vim 打开文件：</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>vim ~/hadoop-2.10.1/etc/hadoop/hdfs-site.xml
</span></span></code></pre></td></tr></table></div></div><p>使用以下内容替换 hdfs-site.xml 中的内容：</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-xml data-lang=xml><span class=line><span class=cl><span class=cp>&lt;?xml version=&#34;1.0&#34; encoding=&#34;UTF-8&#34;?&gt;</span>
</span></span><span class=line><span class=cl><span class=cp>&lt;?xml-stylesheet type=&#34;text/xsl&#34; href=&#34;configuration.xsl&#34;?&gt;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=nt>&lt;configuration&gt;</span>
</span></span><span class=line><span class=cl>    <span class=c>&lt;!-- 指定 HDFS 保存数据的副本数量 --&gt;</span>
</span></span><span class=line><span class=cl>    <span class=nt>&lt;property&gt;</span>
</span></span><span class=line><span class=cl>        <span class=nt>&lt;name&gt;</span>dfs.replication<span class=nt>&lt;/name&gt;</span>
</span></span><span class=line><span class=cl>        <span class=nt>&lt;value&gt;</span>1<span class=nt>&lt;/value&gt;</span>
</span></span><span class=line><span class=cl>    <span class=nt>&lt;/property&gt;</span>
</span></span><span class=line><span class=cl><span class=nt>&lt;/configuration&gt;</span>
</span></span></code></pre></td></tr></table></div></div><p>其中，第 7~8 行，指定 HDFS 文件快的副本数为 1。数据块副本一般为 3 以上，本文章仅作示例，故指定为 1。</p><h4 id=编辑-yarn-sitexml>编辑 yarn-site.xml</h4><p>YARN 是 MapReduce 的调度框架。文件 yarn-site.xml 用配置 YARN 的属性，包括指定 NameNodeManager 获取数据的方式，指定 ResourceManager 的地址，配置 YARN 打印工作日志等。</p><p>使用 vim 打开文件：</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>vim ~/hadoop-2.10.1/etc/hadoop/yarn-site.xml
</span></span></code></pre></td></tr></table></div></div><p>使用以下内容替换 yarn-site.xml 中的内容：</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-xml data-lang=xml><span class=line><span class=cl><span class=cp>&lt;?xml version=&#34;1.0&#34;?&gt;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=nt>&lt;configuration&gt;</span>
</span></span><span class=line><span class=cl>    <span class=c>&lt;!-- 指定 NameNodeManager 获取数据的方式是 shuffle --&gt;</span>
</span></span><span class=line><span class=cl>    <span class=nt>&lt;property&gt;</span>
</span></span><span class=line><span class=cl>        <span class=nt>&lt;name&gt;</span>yarn.nodemanager.aux-services<span class=nt>&lt;/name&gt;</span>
</span></span><span class=line><span class=cl>        <span class=nt>&lt;value&gt;</span>mapreduce_shuffle<span class=nt>&lt;/value&gt;</span>
</span></span><span class=line><span class=cl>    <span class=nt>&lt;/property&gt;</span>
</span></span><span class=line><span class=cl>    <span class=nt>&lt;property&gt;</span>
</span></span><span class=line><span class=cl>        <span class=nt>&lt;name&gt;</span>yarn.nodemanager.env-whitelist<span class=nt>&lt;/name&gt;</span>
</span></span><span class=line><span class=cl>        <span class=nt>&lt;value&gt;</span>JAVA_HOME,HADOOP_COMMON_HOME,HADOOP_HDFS_HOME,HADOOP_CONF_DIR,CLASSPATH_PREPEND_DISTCACHE,HADOOP_YARN_HOME,HADOOP_MAPRED_HOME<span class=nt>&lt;/value&gt;</span>
</span></span><span class=line><span class=cl>    <span class=nt>&lt;/property&gt;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c>&lt;!-- 指定 YARN 中 ResourceManager 所在的主机名 --&gt;</span>
</span></span><span class=line><span class=cl>    <span class=nt>&lt;property&gt;</span>
</span></span><span class=line><span class=cl>        <span class=nt>&lt;name&gt;</span>yarn.resourcemanager.hostname<span class=nt>&lt;/name&gt;</span>
</span></span><span class=line><span class=cl>        <span class=nt>&lt;value&gt;</span>master<span class=nt>&lt;/value&gt;</span>
</span></span><span class=line><span class=cl>    <span class=nt>&lt;/property&gt;</span>
</span></span><span class=line><span class=cl><span class=nt>&lt;/configuration&gt;</span>
</span></span></code></pre></td></tr></table></div></div><p>其中，第 15~19 行配置了 ResourceManager 所在的主机名，如果不进行配置，将会导致 MapReduce 不能获得资源，任务不能执行。</p><h4 id=编辑-mapred-sitexml>编辑 mapred-site.xml</h4><p>文件 mapred-site.xml 主要是配置 MapReduce 的属性，主要是 Hadoop 系统提交的 Map/Reduce 程序运行在 YARN 上。</p><p>首先复制一份 mapred-site.xml.template 文件为 mapred-site.xml，然后打开并进行修改。</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>vim ~/hadoop-2.10.1/etc/hadoop/mapred-site.xml
</span></span></code></pre></td></tr></table></div></div><p>使用以下内容替换 mapred-site.xml 中的内容：</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-xml data-lang=xml><span class=line><span class=cl><span class=cp>&lt;?xml version=&#34;1.0&#34;?&gt;</span>
</span></span><span class=line><span class=cl><span class=cp>&lt;?xml-stylesheet type=&#34;text/xsl&#34; href=&#34;configuration.xsl&#34;?&gt;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=nt>&lt;configuration&gt;</span>
</span></span><span class=line><span class=cl>    <span class=nt>&lt;property&gt;</span>
</span></span><span class=line><span class=cl>        <span class=nt>&lt;name&gt;</span>mapreduce.framework.name<span class=nt>&lt;/name&gt;</span>
</span></span><span class=line><span class=cl>        <span class=nt>&lt;value&gt;</span>yarn<span class=nt>&lt;/value&gt;</span>
</span></span><span class=line><span class=cl>    <span class=nt>&lt;/property&gt;</span>
</span></span><span class=line><span class=cl>    <span class=nt>&lt;property&gt;</span>
</span></span><span class=line><span class=cl>        <span class=nt>&lt;name&gt;</span>mapreduce.application.classpath<span class=nt>&lt;/name&gt;</span>
</span></span><span class=line><span class=cl>        <span class=nt>&lt;value&gt;</span>$HADOOP_MAPRED_HOME/share/hadoop/mapreduce/*:$HADOOP_MAPRED_HOME/share/hadoop/mapreduce/lib/*<span class=nt>&lt;/value&gt;</span>
</span></span><span class=line><span class=cl>    <span class=nt>&lt;/property&gt;</span>
</span></span><span class=line><span class=cl><span class=nt>&lt;/configuration&gt;</span>
</span></span></code></pre></td></tr></table></div></div><p>其中，第 5~8 行为 MapReduce 指定任务调度框架为 YARN。</p><h4 id=编辑-slaves>编辑 slaves</h4><p>slaves 文件为 Hadoop 提供了子节点的主机名。</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>vim ~/hadoop-2.10.1/etc/hadoop/slaves
</span></span></code></pre></td></tr></table></div></div><p>使用以下内容替换 slaves 中的内容：</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>slave1
</span></span><span class=line><span class=cl>slave2
</span></span></code></pre></td></tr></table></div></div><h3 id=复制文件到子节点>复制文件到子节点</h3><p>使用下面的命令将 Hadoop 文件复制到其他节点，本文中为 slave1 和 slave2，命令如下：</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=nb>cd</span> ~/hadoop
</span></span><span class=line><span class=cl>scp -r hadoop-2.10.1 root@slave1:~/hadoop/
</span></span><span class=line><span class=cl>scp -r hadoop-2.10.1 root@slave2:~/hadoop/
</span></span></code></pre></td></tr></table></div></div><h3 id=配置-hadoop-环境变量>配置 Hadoop 环境变量</h3><p>注意，此操作需要同时在所有节点（master，slave1，slave2）都执行一次，操作命令如下：</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>vim ~/.bash_profile
</span></span></code></pre></td></tr></table></div></div><p>将以下内容追加到 .bash_profile 文件末尾：</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-gdscript3 data-lang=gdscript3><span class=line><span class=cl><span class=c1>#HADOOP</span>
</span></span><span class=line><span class=cl><span class=k>export</span> <span class=n>HADOOP_HOME</span><span class=o>=/</span><span class=n>root</span><span class=o>/</span><span class=n>hadoop</span><span class=o>/</span><span class=n>hadoop</span><span class=o>-</span><span class=mf>2.10</span><span class=o>.</span><span class=mi>1</span>
</span></span><span class=line><span class=cl><span class=k>export</span> <span class=n>PATH</span><span class=o>=$</span><span class=n>HADOOP_HOME</span><span class=o>/</span><span class=n>bin</span><span class=p>:</span><span class=o>$</span><span class=n>HADOOP_HOME</span><span class=o>/</span><span class=n>sbin</span><span class=p>:</span><span class=o>$</span><span class=n>PATH</span>
</span></span></code></pre></td></tr></table></div></div><p>然后执行下列命令使环境变量生效：</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=nb>source</span> ~/.bash_profile
</span></span></code></pre></td></tr></table></div></div><h3 id=创建临时文件存放目录>创建临时文件存放目录</h3><p>我们在 core-site.xml 文件中指定了 Hadoop 临时文件存放路径，但是文件夹并没有创建，此操作需要同时在所有节点（master，slave1，slave2）都执行一次，操作命令如下：</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>mkdir /home/hadoop/temp
</span></span></code></pre></td></tr></table></div></div><h2 id=启动集群>启动集群</h2><h3 id=格式化文件系统>格式化文件系统</h3><p>注意，格式化仅需要在第一次使用 Hadoop 集群时进行，后续使用时无需格式化，并且在使用过程中进行格式化，所有文件将会丢失。此操作需要在 master 节点上进行，执行如下命令：</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>hdfs namenode -format
</span></span></code></pre></td></tr></table></div></div><h3 id=启动-hadoop-集群>启动 Hadoop 集群</h3><p>Hadoop 启动或停止服务的脚本均存放在 sbin 目录中，所以切换到 /home/hadoop/hadoop-2.10.1/sbin 目录下，执行以下命令：</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>start-all.sh
</span></span></code></pre></td></tr></table></div></div><p>需要注意的是，在启动过程中，Hadoop 会提示这样的启动方式已经过时，使用如下启动方式即可规避过时提示：</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>start-dfs.sh
</span></span><span class=line><span class=cl>start-yarn.sh
</span></span></code></pre></td></tr></table></div></div><h3 id=查看进程是否启动成功>查看进程是否启动成功</h3><p>在 master 节点终端执行 jps 命令，在打印结果中会看到四个进程，分别是 NodeManager、SecondaryNameNode、ResourceManager、Jps。如果出现了这四个进程表示启动成功。结果如下：</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>root@master:~/hadoop/hadoop-2.10.1/sbin## jps
</span></span><span class=line><span class=cl>17874 NameNode
</span></span><span class=line><span class=cl>18070 SecondaryNameNode
</span></span><span class=line><span class=cl>18281 ResourceManager
</span></span><span class=line><span class=cl>18554 Jps
</span></span></code></pre></td></tr></table></div></div><p>此时在 slave1 和 slave2 的节点的终端执行 jps 命令，在输出结果中会看到三个进程，分别是 Jps、NodeManager、DataNode，如果出现了这三个进程表示子节点进程启动成功。结果如下：</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>root@slave1:~## jps
</span></span><span class=line><span class=cl>15776 NodeManager
</span></span><span class=line><span class=cl>15639 DataNode
</span></span><span class=line><span class=cl>16106 Jps
</span></span></code></pre></td></tr></table></div></div><h3 id=查看-webui>查看 WebUI</h3><h4 id=hadoop-页面>Hadoop 页面</h4><p>如果要在宿主机上访问虚拟机 master 节点的 WebUI，需要先将虚拟机的防火墙关闭（此处仅仅是做示例，生产环境不建议这么做），然后访问虚拟机 master 节点 IP:50070 即可。</p><p>防火墙相关命令如下：</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span><span class=lnt>6
</span><span class=lnt>7
</span><span class=lnt>8
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=c1>## 暂时关闭防火墙</span>
</span></span><span class=line><span class=cl>systemctl stop firewalld
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1>## 永久关闭防火墙</span>
</span></span><span class=line><span class=cl>systemctl disable firewalld
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1>## 启用防火墙</span>
</span></span><span class=line><span class=cl>systemctl <span class=nb>enable</span> firewalld
</span></span></code></pre></td></tr></table></div></div><p>例如本例中 master 节点地址为 192.168.61.128，则访问 192.168.61.128:50070，页面如下图：</p><p><img src=/posts/getting-to-know-hadoop/assets/20200926201409.webp width=2090 height=1219 srcset="/posts/getting-to-know-hadoop/assets/20200926201409_hu_e6c5372cb8e8c4a3.webp 480w, /posts/getting-to-know-hadoop/assets/20200926201409_hu_286f0f61bbffca5.webp 1024w" loading=lazy alt="Hadoop NameNode Web 管理界面" class=gallery-image data-flex-grow=171 data-flex-basis=411px></p><h4 id=yarn-页面>YARN 页面</h4><p>如上例，与 Hadoop 管理页面不同的是，YARN Web 页面地址端口是 8088，页面如下图：</p><p><img src=/posts/getting-to-know-hadoop/assets/20200926203912.webp width=3208 height=1259 srcset="/posts/getting-to-know-hadoop/assets/20200926203912_hu_a69329e7a82f114d.webp 480w, /posts/getting-to-know-hadoop/assets/20200926203912_hu_b3f731a5b6cbb7de.webp 1024w" loading=lazy alt="YARN ResourceManager Web 管理界面" class=gallery-image data-flex-grow=254 data-flex-basis=611px></p><h2 id=运行实例>运行实例</h2><p>在 Hadoop 自带的 examples 中有一种利用分布式系统计算圆周率的方法，采用的是拟蒙特卡罗（Quasi-Monte Carlo）算法来对 $ \pi $ 的值进行估算。下面通过运行该程序来检验 Hadoop 集群是否安装配置成功。</p><p>在 master 节点终端中执行下面的命令：</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>hadoop jar hadoop-2.10.1/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.10.1.jar pi <span class=m>100</span> <span class=m>100000</span>
</span></span></code></pre></td></tr></table></div></div><p>Hadoop 的命令类似 Java 命令，通过 jar 指定要运行的程序所在的 jar 包 hadoop-mapreduce-examples-2.10.1.jar。参数 pi 表示需要计算的圆周率 $ \pi $。后面两个参数中，100 是指要运行 100 次 map，100000 表示每个 map 的任务次数，即每个节点要模拟飞镖 100000 次。执行过程及结果如下图：</p><p><img src=/posts/getting-to-know-hadoop/assets/20200926210747.webp width=3840 height=1295 srcset="/posts/getting-to-know-hadoop/assets/20200926210747_hu_a805fca0c7ebd912.webp 480w, /posts/getting-to-know-hadoop/assets/20200926210747_hu_dc6f8beebf62f2e3.webp 1024w" loading=lazy alt="Pi 计算作业执行过程" class=gallery-image data-flex-grow=296 data-flex-basis=711px></p><p><img src=/posts/getting-to-know-hadoop/assets/20200926211331.webp width=1767 height=840 srcset="/posts/getting-to-know-hadoop/assets/20200926211331_hu_799d2b8b3d445d6e.webp 480w, /posts/getting-to-know-hadoop/assets/20200926211331_hu_5e26f45e2970c498.webp 1024w" loading=lazy alt="Pi 计算作业执行结果" class=gallery-image data-flex-grow=210 data-flex-basis=504px></p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>Job Finished in 131.634 seconds
</span></span><span class=line><span class=cl>Estimated value of Pi is 3.14158440000000000000
</span></span></code></pre></td></tr></table></div></div><p>至此，Hadoop 环境配置完成。</p><h2 id=备注>备注</h2><p>如果在执行 mapreduce 任务中报错如 <a class=link href=https://stackoverflow.com/questions/21005643/container-is-running-beyond-memory-limits target=_blank rel=noopener>此问题</a> 的描述，参考 <a class=link href=https://web.archive.org/web/20170610145449/http://hortonworks.com/blog/how-to-plan-and-configure-yarn-in-hdp-2-0/ target=_blank rel=noopener>此篇文章</a>，需要在 mapred-site.xml 文件中添加下列配置：</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-xml data-lang=xml><span class=line><span class=cl><span class=nt>&lt;property&gt;</span>
</span></span><span class=line><span class=cl>    <span class=nt>&lt;name&gt;</span>mapreduce.map.memory.mb<span class=nt>&lt;/name&gt;</span>
</span></span><span class=line><span class=cl>    <span class=nt>&lt;value&gt;</span>4096<span class=nt>&lt;/value&gt;</span>
</span></span><span class=line><span class=cl><span class=nt>&lt;/property&gt;</span>
</span></span><span class=line><span class=cl><span class=nt>&lt;property&gt;</span>
</span></span><span class=line><span class=cl>    <span class=nt>&lt;name&gt;</span>mapreduce.reduce.memory.mb<span class=nt>&lt;/name&gt;</span>
</span></span><span class=line><span class=cl>    <span class=nt>&lt;value&gt;</span>8192<span class=nt>&lt;/value&gt;</span>
</span></span><span class=line><span class=cl><span class=nt>&lt;/property&gt;</span>
</span></span><span class=line><span class=cl><span class=nt>&lt;property&gt;</span>
</span></span><span class=line><span class=cl>    <span class=nt>&lt;name&gt;</span>mapreduce.map.java.opts<span class=nt>&lt;/name&gt;</span>
</span></span><span class=line><span class=cl>    <span class=nt>&lt;value&gt;</span>-Xmx3072m<span class=nt>&lt;/value&gt;</span>
</span></span><span class=line><span class=cl><span class=nt>&lt;/property&gt;</span>
</span></span><span class=line><span class=cl><span class=nt>&lt;property&gt;</span>
</span></span><span class=line><span class=cl>    <span class=nt>&lt;name&gt;</span>mapreduce.reduce.java.opts<span class=nt>&lt;/name&gt;</span>
</span></span><span class=line><span class=cl>    <span class=nt>&lt;value&gt;</span>-Xmx6144m<span class=nt>&lt;/value&gt;</span>
</span></span><span class=line><span class=cl><span class=nt>&lt;/property&gt;</span>
</span></span></code></pre></td></tr></table></div></div></section><footer class=article-footer><section class=article-copyright><svg class="icon icon-tabler icon-tabler-copyright" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="12" r="9"/><path d="M14.5 9a3.5 4 0 100 6"/></svg>
<span>Licensed under CC BY-NC-SA 4.0</span></section></footer><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css integrity=sha384-n8MVd4RsNIU0tAv4ct0nTaAbDJwPJzDEaqSD1odI+WdtXRGWt2kTvGFasHpSy3SV crossorigin=anonymous><script src=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js integrity=sha384-XjKyOOlGwcjNTAIQHIpgOno0Hl1YQqzUOEleOLALmuqehneUG+vnGctmUb0ZY0l8 crossorigin=anonymous defer></script><script src=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js integrity=sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05 crossorigin=anonymous defer></script><script>window.addEventListener("DOMContentLoaded",()=>{renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1},{left:"\\(",right:"\\)",display:!1},{left:"\\[",right:"\\]",display:!0}],ignoredClasses:["gist"]})})</script></article><aside class=related-content--wrapper><h2 class=section-title>Related content</h2><div class=related-content><div class="flex article-list--tile"><article><a href=/posts/spark-distributed-programming/><div class=article-details><h2 class=article-title>Spark 分布式内存计算框架</h2></div></a></article><article><a href=/posts/mapreduce-distributed-programming/><div class=article-details><h2 class=article-title>MapReduce 分布式编程</h2></div></a></article><article><a href=/posts/hdfs-file-system/><div class=article-details><h2 class=article-title>HDFS 文件管理</h2></div></a></article></div></div></aside><script src=https://giscus.app/client.js data-repo=jinggqu/jinggqu.github.io data-repo-id="MDEwOlJlcG9zaXRvcnkxNDkyMTI2MDk=" data-category=Announcements data-category-id=DIC_kwDOCOTNwc4Ca4Al data-mapping=pathname data-strict=0 data-reactions-enabled=1 data-emit-metadata=0 data-input-position=bottom data-theme=light data-lang=en data-loading crossorigin=anonymous async></script><script>function setGiscusTheme(e){let t=document.querySelector("iframe.giscus-frame");t&&t.contentWindow.postMessage({giscus:{setConfig:{theme:e}}},"https://giscus.app")}(function(){addEventListener("message",t=>{if(event.origin!=="https://giscus.app")return;e()}),window.addEventListener("onColorSchemeChange",e);function e(){setGiscusTheme(document.documentElement.dataset.scheme==="light"?"light":"dark")}})()</script><footer class=site-footer><section class=copyright>&copy;
2018 -
2025 Anthony's blog</section><section class=powerby>Built with <a href=https://gohugo.io/ target=_blank rel=noopener>Hugo</a><br>Theme <b><a href=https://github.com/CaiJimmy/hugo-theme-stack target=_blank rel=noopener data-version=3.29.0>Stack</a></b> designed by <a href=https://jimmycai.com target=_blank rel=noopener>Jimmy</a></section></footer><div class=pswp tabindex=-1 role=dialog aria-hidden=true><div class=pswp__bg></div><div class=pswp__scroll-wrap><div class=pswp__container><div class=pswp__item></div><div class=pswp__item></div><div class=pswp__item></div></div><div class="pswp__ui pswp__ui--hidden"><div class=pswp__top-bar><div class=pswp__counter></div><button class="pswp__button pswp__button--close" title="Close (Esc)"></button>
<button class="pswp__button pswp__button--share" title=Share></button>
<button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>
<button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button><div class=pswp__preloader><div class=pswp__preloader__icn><div class=pswp__preloader__cut><div class=pswp__preloader__donut></div></div></div></div></div><div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap"><div class=pswp__share-tooltip></div></div><button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
</button>
<button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)"></button><div class=pswp__caption><div class=pswp__caption__center></div></div></div></div></div><script src=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.js integrity="sha256-ePwmChbbvXbsO02lbM3HoHbSHTHFAeChekF1xKJdleo=" crossorigin=anonymous defer></script><script src=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe-ui-default.min.js integrity="sha256-UKkzOn/w1mBxRmLLGrSeyB4e1xbrp4xylgAWb3M42pU=" crossorigin=anonymous defer></script><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/default-skin/default-skin.min.css crossorigin=anonymous><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.css crossorigin=anonymous></main></div><script src=https://cdn.jsdelivr.net/npm/node-vibrant@3.1.6/dist/vibrant.min.js integrity="sha256-awcR2jno4kI5X0zL8ex0vi2z+KMkF24hUW8WePSA9HM=" crossorigin=anonymous></script><script type=text/javascript src=/ts/main.1e9a3bafd846ced4c345d084b355fb8c7bae75701c338f8a1f8a82c780137826.js defer></script><script>(function(){const e=document.createElement("link");e.href="https://fonts.googleapis.com/css2?family=Lato:wght@300;400;700&display=swap",e.type="text/css",e.rel="stylesheet",document.head.appendChild(e)})()</script></body></html>